{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import sqlite3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShipResNet(nn.Module):\n",
    "    def __init__(self, base_model_fn=models.resnet18, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Preprocessing layer: project (2 channels VV+VH) -> 3 channels\n",
    "        self.input_proj = nn.Conv2d(in_channels=2, out_channels=3, kernel_size=1)\n",
    "\n",
    "        # Load base model and strip off the final fully connected layer\n",
    "        base_model = base_model_fn(pretrained=pretrained)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n",
    "\n",
    "        # Regression head: output 8 values\n",
    "        self.head = nn.Linear(in_features=512, out_features=8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)  # (B, 2, H, W) -> (B, 3, H, W)\n",
    "        x = self.feature_extractor(x)  # (B, C, 1, 1)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, df, clip_percentiles=(2, 98)):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.clip_percentiles = clip_percentiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        img = np.load(row['image_path'])  # shape (2, H, W)\n",
    "        if img.ndim != 3:\n",
    "            raise ValueError(f\"Unexpected shape {img.shape} in {row['image_path']}\")\n",
    "\n",
    "        # Normalize per-channel\n",
    "        img = img.astype(np.float32)\n",
    "        for c in range(img.shape[0]):\n",
    "            band = img[c]\n",
    "            band = np.nan_to_num(band, nan=0.0)\n",
    "            vmin, vmax = np.percentile(band, self.clip_percentiles)\n",
    "            band = np.clip(band, vmin, vmax)\n",
    "            band = (band - vmin) / (vmax - vmin + 1e-5)\n",
    "            img[c] = band\n",
    "\n",
    "        # Convert to tensor\n",
    "        image_tensor = torch.from_numpy(img)\n",
    "\n",
    "        # Prepare target values\n",
    "        heading_deg = row['heading']\n",
    "        heading_rad = np.deg2rad(heading_deg) if pd.notnull(heading_deg) else 0.0\n",
    "        heading_x = np.cos(heading_rad)\n",
    "        heading_y = np.sin(heading_rad)\n",
    "\n",
    "        target = torch.tensor([\n",
    "            row['sog'],\n",
    "            row['length'],\n",
    "            row['width'] if pd.notnull(row['width']) else 0.0,\n",
    "            row['draft'] if pd.notnull(row['draft']) else 0.0,\n",
    "            heading_x,\n",
    "            heading_y,\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        return image_tensor, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(\n",
    "    model, dataset, num_epochs=10, batch_size=32, lr=1e-4, val_split=0.1, device=\"cuda\"\n",
    "):\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Split dataset\n",
    "    n = len(dataset)\n",
    "    val_size = int(val_split * n)\n",
    "    train_size = n - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for imgs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "        avg_loss = total_loss / train_size\n",
    "        print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, targets in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                preds = model(imgs)\n",
    "                val_loss += criterion(preds, targets).item() * imgs.size(0)\n",
    "\n",
    "        avg_val = val_loss / val_size\n",
    "        print(f\"Val Loss: {avg_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Load dataframe\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect(\"../../data/ais.db\")\n",
    "df = pd.read_sql_query(\"SELECT * FROM ais\", conn)\n",
    "\n",
    "# Optional: shuffle or subsample for a quick first test\n",
    "# df = df.sample(frac=0.1).reset_index(drop=True)\n",
    "\n",
    "# Create dataset\n",
    "dataset = ShipDataset(df)\n",
    "\n",
    "# Init model\n",
    "model = ShipResNet(num_outputs=8)\n",
    "\n",
    "# Kick off training\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    num_epochs=10,\n",
    "    batch_size=32,\n",
    "    lr=1e-4,\n",
    "    val_split=0.1,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ships-env)",
   "language": "python",
   "name": "ships-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
